{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zeroday_lbl_x = pd.read_csv(\"zeroday_lbl_x.csv\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zeroday_lbl_y = pd.read_csv(\"zeroday_lbl_y.csv\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('zeroday_lbl_wordsize.pkl', 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "    word_size = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('zeroday_vocab.pkl', 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2795"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_y = np.vstack((np.eye(3), [0]*3))\n",
    "onehot_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zeroday_onehot_y = [onehot_y[item] for item in zeroday_lbl_y]\n",
    "# zeroday_onehot_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroday_onehot_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_x = np.vstack((np.eye(len(vocab)), [0]*len(vocab)))\n",
    "onehot_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zeroday_onehot_x = [onehot_x[item] for item in zeroday_lbl_x]\n",
    "# zeroday_onehot_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroday_onehot_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Batcher():\n",
    "    def __init__(self, x, y, x_batch_size):\n",
    "        self.split_size = int(len(x)*0.8)\n",
    "        self.train_x = x[:self.split_size]\n",
    "        self.train_y = y[:self.split_size]\n",
    "        self.train_size = x_batch_size[:self.split_size]\n",
    "        self.test_x = x[self.split_size:]\n",
    "        self.test_y = y[self.split_size:]\n",
    "        self.test_size = x_batch_size[self.split_size:]\n",
    "        self.start = 0\n",
    "    def next_batch(self, batch_size):\n",
    "        s_index = self.start\n",
    "        e_index = self.start + batch_size\n",
    "        if e_index >= self.split_size:\n",
    "            self.start = 0\n",
    "            s_index = self.start\n",
    "            e_index = self.start + batch_size\n",
    "        self.start = e_index\n",
    "        return self.train_x[s_index:e_index], self.train_y[s_index:e_index], self.train_size[s_index:e_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zeroday_batch = Batcher(zeroday_onehot_x, zeroday_onehot_y, word_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_data, batch_labels, batch_seqlen = zeroday_batch.next_batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]),\n",
       " array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  0.,  1.],\n",
       "        [ 0.,  0.,  1.],\n",
       "        [ 0.,  0.,  1.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]]), array([[ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  0.,  1.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(batch_labels[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[83, 89]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_seqlen[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1527"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1527.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>80.619515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.025809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  1527.000000\n",
       "mean     80.619515\n",
       "std       9.025809\n",
       "min      49.000000\n",
       "25%      74.000000\n",
       "50%      82.000000\n",
       "75%      87.000000\n",
       "max     114.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_size_pd = pd.DataFrame(word_size)\n",
    "word_size_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "166   105\n",
       "167   105\n",
       "181   114\n",
       "218   106\n",
       "291   106\n",
       "317   109\n",
       "321   101\n",
       "364   101\n",
       "394   104\n",
       "438   102\n",
       "445   109\n",
       "900   114\n",
       "1437  102\n",
       "1438  102\n",
       "1441  102"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_size_pd[word_size_pd[0]>100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1527, 114)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zeroday_lbl_y), len(zeroday_lbl_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_max_len = len(zeroday_lbl_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'bi-GRU/bidirectional_rnn/fw/fw/transpose:0' shape=(?, 114, 128) dtype=float32>, <tf.Tensor 'bi-GRU/ReverseSequence:0' shape=(?, 114, 128) dtype=float32>)\n",
      "Tensor(\"bi-GRU/concat:0\", shape=(?, 114, 256), dtype=float32)\n",
      "Tensor(\"bi-GRU/Reshape:0\", shape=(?, 256), dtype=float32)\n",
      "Tensor(\"output/xw_plus_b:0\", shape=(?, 3), dtype=float32)\n",
      "Tensor(\"output/Reshape:0\", shape=(?, 114, 3), dtype=float32)\n",
      "Tensor(\"loss/ArgMax:0\", shape=(?, 114), dtype=int64)\n",
      "Tensor(\"loss/SparseSoftmaxCrossEntropyWithLogits/Reshape_2:0\", shape=(?, 114), dtype=float32)\n",
      "Tensor(\"loss/Sum:0\", shape=(?, 114), dtype=float32)\n",
      "Tensor(\"loss/Sign:0\", shape=(?, 114), dtype=float32)\n",
      "Tensor(\"loss/Mul:0\", shape=(?, 114), dtype=float32)\n",
      "Tensor(\"loss/Sum_1:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"loss/div:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"loss/loss:0\", shape=(), dtype=float32)\n",
      "Tensor(\"valid/ArgMax:0\", shape=(?, 114), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_steps = 500\n",
    "batch_size = 100\n",
    "display_step = 50\n",
    "\n",
    "# Network Parameters\n",
    "seq_max_len = len(zeroday_lbl_y[0]) # Sequence max length\n",
    "forward_units = 128 # hidden layer num of features\n",
    "backward_units = 128 # hidden layer num of features\n",
    "n_classes = 3 # linear sequence or not\n",
    "\n",
    "# Batcher zeroday_batch\n",
    "zeroday_batch = Batcher(zeroday_onehot_x, zeroday_onehot_y, word_size)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, seq_max_len, len(vocab)])\n",
    "y = tf.placeholder(\"float\", [None, seq_max_len, n_classes])\n",
    "# A placeholder for indicating each sequence length\n",
    "seqlen = tf.placeholder(tf.int32, [None,])\n",
    "\n",
    "    \n",
    "with tf.variable_scope(\"bi-GRU\") as scope:\n",
    "    # Define a lstm cell with tensorflow\n",
    "    encoder_fw = tf.contrib.rnn.GRUCell(forward_units)\n",
    "    encoder_bw = tf.contrib.rnn.GRUCell(backward_units)\n",
    "\n",
    "    outputs, _ = tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_fw, \n",
    "                                            cell_bw=encoder_bw, \n",
    "                                            inputs=x,\n",
    "                                            sequence_length=seqlen,\n",
    "                                            dtype=tf.float32)\n",
    "\n",
    "    print(outputs)\n",
    "    output = tf.concat(outputs, 2)\n",
    "    print(output)\n",
    "#     batch_size = output.get_shape().as_list()[0]\n",
    "    reshape = tf.reshape(output, [-1, forward_units + backward_units])\n",
    "    print(reshape)\n",
    "    \n",
    "with tf.variable_scope(\"output\"):\n",
    "    softmax_w = tf.get_variable(\"softmax_w\",\n",
    "                                shape=[forward_units + backward_units, n_classes],\n",
    "                                initializer=tf.truncated_normal_initializer(stddev=0.05),\n",
    "                                dtype=tf.float32)\n",
    "    softmax_b = tf.get_variable(\"softmax_b\",\n",
    "                                shape=[n_classes],\n",
    "                                initializer=tf.constant_initializer(value=0.),\n",
    "                                dtype=tf.float32)\n",
    "    xw_plus_b = tf.nn.xw_plus_b(reshape, softmax_w, softmax_b)\n",
    "    print(xw_plus_b)\n",
    "    logits = tf.reshape(xw_plus_b, [-1, seq_max_len, n_classes])\n",
    "    print(logits)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    y_arg = tf.argmax(y, axis=2)\n",
    "    print(y_arg)\n",
    "    fake_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y_arg)\n",
    "    print(fake_loss)\n",
    "    y_sum = tf.reduce_sum(y, axis=2)\n",
    "    print(y_sum)\n",
    "    mask = tf.cast(tf.sign(y_sum), dtype=tf.float32)\n",
    "    print(mask)\n",
    "    loss_per_example_per_step = tf.multiply(fake_loss, mask)\n",
    "    print(loss_per_example_per_step)\n",
    "    loss_per_example_sum = tf.reduce_sum(loss_per_example_per_step, reduction_indices=[1])\n",
    "    print(loss_per_example_sum)\n",
    "    loss_per_example_average = tf.div(x=loss_per_example_sum,\n",
    "                                      y=tf.cast(seqlen, tf.float32))\n",
    "    print(loss_per_example_average)\n",
    "    loss = tf.reduce_mean(loss_per_example_average, name=\"loss\")\n",
    "    print(loss)\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss, name=\"train_op\")\n",
    "    \n",
    "with tf.name_scope(\"valid\"):\n",
    "    predict = tf.argmax(logits, axis=2)\n",
    "    print(predict)\n",
    "    fake_accuracy = tf.cast(tf.equal(predict, y_arg), dtype=tf.float32)\n",
    "    accuracy_matrix = tf.multiply(fake_accuracy, mask)\n",
    "    accuracy_per_example = tf.div(x=tf.reduce_sum(accuracy_matrix, 1),\n",
    "                                  y=tf.cast(seqlen, tf.float32))\n",
    "    accuracy = tf.reduce_mean(accuracy_per_example, name=\"valid_accuracy\")\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100, Minibatch Loss= 0.910922, Training Accuracy= 0.96366\n",
      "Testing Accuracy: 0.95113\n",
      "Step 5000, Minibatch Loss= 0.018893, Training Accuracy= 0.99567\n",
      "Testing Accuracy: 0.99287\n",
      "Step 10000, Minibatch Loss= 0.004648, Training Accuracy= 0.99879\n",
      "Testing Accuracy: 0.995548\n",
      "Step 15000, Minibatch Loss= 0.000220, Training Accuracy= 1.00000\n",
      "Testing Accuracy: 0.997138\n",
      "Step 20000, Minibatch Loss= 0.000085, Training Accuracy= 1.00000\n",
      "Testing Accuracy: 0.998171\n",
      "Step 25000, Minibatch Loss= 0.000049, Training Accuracy= 1.00000\n",
      "Testing Accuracy: 0.998658\n",
      "Step 30000, Minibatch Loss= 0.000017, Training Accuracy= 1.00000\n",
      "Testing Accuracy: 0.99862\n",
      "Step 35000, Minibatch Loss= 0.000082, Training Accuracy= 1.00000\n",
      "Testing Accuracy: 0.99862\n",
      "Step 40000, Minibatch Loss= 0.000062, Training Accuracy= 1.00000\n",
      "Testing Accuracy: 0.998584\n",
      "Step 45000, Minibatch Loss= 0.000015, Training Accuracy= 1.00000\n",
      "Testing Accuracy: 0.998584\n",
      "Step 50000, Minibatch Loss= 0.000009, Training Accuracy= 1.00000\n",
      "Testing Accuracy: 0.998584\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.998584\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = \"./biGRU/\"\n",
    "saver = tf.train.Saver(tf.global_variables(), max_to_keep=15)\n",
    "module_file = tf.train.latest_checkpoint(LOG_DIR)\n",
    "\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "tf.summary.scalar(\"acc\", accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    train_writer = tf.summary.FileWriter(LOG_DIR + \"train/\", sess.graph)\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "#     saver.restore(sess, module_file)\n",
    "\n",
    "    for step in range(1, training_steps + 1):\n",
    "        # Get batch data\n",
    "        batch_x, batch_y, batch_seqlen = zeroday_batch.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        _, summary_ = sess.run([train_op, merged], feed_dict={x: batch_x, y: batch_y, seqlen: batch_seqlen})\n",
    "        train_writer.add_summary(summary_, step)\n",
    "        \n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch accuracy & loss\n",
    "            cost, acc = sess.run([loss, accuracy], feed_dict={x: batch_x, y: batch_y, seqlen: batch_seqlen})\n",
    "            print(\"Step \" + str(step*batch_size) + \\\n",
    "                  \", Minibatch Loss= \" + \"{:.6f}\".format(cost) + \\\n",
    "                  \", Training Accuracy= \" + \"{:.5f}\".format(acc))\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            test_data = zeroday_batch.test_x\n",
    "            test_label = zeroday_batch.test_y\n",
    "            test_seqlen = zeroday_batch.test_size\n",
    "            test_acc = sess.run(accuracy, feed_dict={x: test_data, y: test_label, seqlen: test_seqlen})\n",
    "            print(\"Testing Accuracy:\", test_acc)\n",
    "        if step % 5 == 0:\n",
    "            saver.save(sess, LOG_DIR+\"zeroday.ckpt\", global_step=step)\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy\n",
    "    test_data = zeroday_batch.test_x\n",
    "    test_label = zeroday_batch.test_y\n",
    "    test_seqlen = zeroday_batch.test_size\n",
    "    test_acc = sess.run(accuracy, feed_dict={x: test_data, y: test_label, seqlen: test_seqlen})\n",
    "    print(\"Testing Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
